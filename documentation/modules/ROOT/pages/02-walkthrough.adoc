= Demo Walkthrough
include::_attributes.adoc[]

[#legacy]
== Introduction to Legacy Application

. Show the coolstore without the inventory.  You can get the URL of the coolstore UI by running the following command
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
COOLSTORE_URL=http://$(oc get route coolstore-ui -o jsonpath='{.spec.host}' -n cdc-coolstore)
----
+
. Explain that the inventory comes from another system.  A legacy system.
. Navigate to the legacy system.  You can get the URL to the legacy application by running the following command in the demo shell:
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
LEGACY_URL=http://$(oc get route www -o jsonpath='{.spec.host}' -n ${PROJECT_PREFIX}-dev)
----
+
. Show that the inventory database is currently empty by clicking on the "Inventory" navbar
+
image::legacy-inventory-navbar.png[]
+
. Show that the legacy system accepts an upload of inventory data by clicking on the `Home` navbar element
. Next click on `Choose file` button which should open up a window like so:
+
image::legacy-inventory-upload.png[]
+
. In the directory shown (`$DEMO_HOME/example`) choose the `coolstore-inventory.csv'
. Click `Load File`
. You should now see a screen of all the imported inventory.  
+
[IMPORTANT]
====
Keep this tab open as we will revisit this page later
====
+
image:loaded-inventory.png[]
+
. Reopen the `$COOLSTORE_URL` and notice that inventory has not been updated still

[#producerconsumer]
== Kafka: Producers, Consumers, and Groups

In this demo we want to show the notion of producers and consumers and ideally topics without any of the k8 overlays

See link:https://medium.com/@TimvanBaarsen/apache-kafka-cli-commands-cheat-sheet-a6f06eac01b#fe4f[here] for some commands that can be used.

For this we setup 4 terminals.  

. All four get setup in the same way.  Run the following command first in each:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
# from the root of this repo
docker run -it -v ~/.kube:/home/jboss/.kube -v ~/.oh-my-zsh:/home/jboss/.oh-my-zsh -v $(pwd):/workspaces/cdc-data-monolith -w /workspaces/cdc-data-monolith quay.io/mhildenb/cdc-demo-shell /bin/zsh
----
+
. Once in the docker shell, ensure you are logged in (one you are logged into one you should be logged into all)
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc whoami
----
+
[.console-output]
[source,bash,subs="attributes+,+macros"]
----
opentlc-mgr
----
+
. Next run the following command to setup your environment
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
. pass:[${DEMO_HOME}]/example/scripts/producer-consumer-setup.sh
----
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 1 (Producer)::
+
--
Terminal one is for producing information on a topic.  Run the following command to get started

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}]
----

NOTE: The terminal is ready to take input on the topic when you see the chevron (`>`)

--
Terminal 2::
+
--
Terminal 2 will be our first consumer in the group `consumer-group-1`

Run the following command to get it started:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}] --group consumer-group-1
----
--
Terminal 3::
+
--
Terminal 3 will be our second consumer in the group `consumer-group-1`

Run the following command to get it started:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}] --group consumer-group-1
----
--
Terminal 4::
+
--
Terminal 4 will be our first consumer in the group `consumer-group-solo`

Run the following command to get it started:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}] --group consumer-group-solo
----
--
====
+
. Enter the following
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 1 (Producer)::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
Test Event 1
----
--
====
+
. You should notice output in one of Terminal 2 or 3 and Terminal 4
+
image::four-terminal-producer-consumer.png[]
+
. Enter the following
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 1 (Producer)::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
Test Event 2
----
--
====
+
. You should notice output in the same of Terminal 2 and 3 that received the event before and Terminal 4
. Next kill the consumer in either Terminal 2 or 3, whichever one got the previous two events, with kbd:[ctrl+c]
. Enter the following
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 1 (Producer)::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
Test Event 3
----
--
====
+
. This time the other terminal of `consumer-group-1` should get the message as should Terminal 4
. Now kill the consumer in Terminal 4 with kbd:[ctrl+c]
. Enter the following:
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 1 (Producer)::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
Test Event 4
----
--
====
+
. You should only see the event appear in the remaining connected terminal
. Finally, let's see how the consumer groups have gone.  Let's use the `kafka-consumer-groups` command to see:
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 4::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group consumer-group-solo
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group consumer-group-1
----
--
====
+
. Output should be similar to:
+
[.console-output]
[source,bash,subs="attributes+,+macros"]
----
Consumer group 'consumer-group-solo' has no active members.

GROUP               TOPIC                    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
consumer-group-solo test-producer-consumer   0          16              17              1               -               -               -
----
+
[.console-output]
[source,bash,subs="attributes+,+macros"]
----
GROUP            TOPIC                    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                      HOST            CLIENT-ID
consumer-group-1 test-producer-consumer   0          17              17              0               consumer-consumer-group-1-1-c2d8588c-996e-47df-bb46-66d948d4a9ea /10.128.2.16    consumer-consumer-group-1-1
----
+
. Next, let's reset the offset of the only consumer group that is currently offline (has no active members)
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 4::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --reset-offsets --to-earliest --group consumer-group-solo --topic pass:[${TOPIC}] --execute
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
GROUP                          TOPIC                          PARTITION  NEW-OFFSET     
consumer-group-solo            test-producer-consumer-1       0          0              
----
--
====
+
. Finally, let's restart a consumer of the `consumer-group-solo`
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 4::
+
--
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc exec -it demo-kafka-0 -n pass:[${KAFKA_PROJECT}] -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}] --group consumer-group-solo
----
--
====
+
. After a few seconds you should see the following output
+
[tabs,subs="attributes+,+macros"]	
====	
Terminal 4::
+
--
[.console-output]
[source,bash,subs="attributes+,+macros"]
----
Test Event 1
Test Event 2
Test Event 3
Test Event 4
Test Event 5
----
--
====
. Which shows that our offset has been reset to the start causing us to reread the events

[#strimzi]
== Strimzi and AMQStreams Operator

[#kafkaconnect]
== Kafka Connect

[#debeziumconnector]
== Enable Debezium Connector

=== Configure SQL Database

See last part of `ansible/demo/templates/configmap-data-sql.yaml.j2` and instructions link:https://debezium.io/documentation/reference/connectors/sqlserver.html#_enabling_cdc_on_the_sql_server_database[here]

=== Create Connect

See: `ansible/demo/templates/kafka-connect.yaml.j2`

This is for metadata about the connector (I think)

=== Create Connector

See: `ansible/demo/templates/kafka-connector-mssql.yaml.j2`

[#demonstratedbz]
== Demonstrate Debezium

. Connect to database using Adminer per instructions xref:03-appendix.adoc#mssql[here]
. In another terminal watch where the order events will go
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc exec -it demo-kafka-0 -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mssql-server-linux.dbo.Orders --from-beginning
----
+
. Go to adminer and create a new entry

== Generate legacy-order-adaptor

=== Create JSON to POJO

. Start with some example `.json` generated from CDC event in xref:02-walkthrough.adoc#demonstratedbz[this section]
. Navigate to link:http://www.jsonschema2pojo.org/[this site] and paste in the json per screenshot
+
image::json2pojo.png[]
+
. Click the link to download the zip file
. expand into the `functions` directory
. Update tests to show JSON to POJO working

[#deploylegacyconsumer]
=== Deploy Legacy Consumer

Run the following ansible command to create a deployment and configmap for the connector

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
ansible-playbook -i pass:[${DEMO_HOME}]/ansible/demo/inventory \
    pass:[${DEMO_HOME}]/ansible/demo/main.yaml \
    -e "ACTION=consumer_create" 
----
