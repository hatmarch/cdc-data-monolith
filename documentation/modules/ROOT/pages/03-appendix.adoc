= Appendix
include::_attributes.adoc[]

[#querysql]
== Querying the SQL database

In a pinch you can query the sql database like this (NOTE: assumes this is run from the project where the DB server is)

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc exec deployment/mssql-server-linux -- /opt/mssql-tools/bin/sqlcmd -S mssql-server-linux -U sa -P 'Password!' -q 'SELECT * FROM InternationalDB.dbo.Orders'
----

Alternatively (originally from lab)

----
oc exec deployment/mssql-server-linux -- /opt/mssql-tools/bin/sqlcmd -S mssql-server-linux -U sa -P Password! -d InternationalDB -Q "select top 5 * from dbo.Orders where OrderUser='admin'"
----

[#kafkatopicdebug]
== Debugging Kafka Topics

You can run a consumer to see all that's been posted to a kafka topic by running the following command (NOTE: This assumes that command is run in the context of the current kafka project)

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc exec -it demo-kafka-0 -- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mssql-server-linux.dbo.Orders --from-beginning
----

[#mssql]
== Connect and View MS SQL Database

You can use adminer to connect to the mssql database.  Run this command from the VSCode terminal (assuming your current project is the project that houses the SQL Server)

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc port-forward svc/mssql-server-linux 1433:1433
----

Then, back on your host machine, run the following in a terminal

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
docker run --rm -p 8080:8080 -e ADMINER_DEFAULT_SERVER=docker.for.mac.localhost:1433 adminer
----

[IMPORTANT]
====
Make sure the port after `docker.for.mac.localhost` matches the port that you are forwarding from the VSCode terminal
====

On your local machine, navigate to port 8080

image::adminer.png[]

* *Username*: `sa`
* *Password*: `Password!`
* *Database*: `InternationalDB`

[#build]
== Building the Legacy App Consumer

To build the application that is going to be watching for CDC events, you can do the following:

. Issue the following command (ensuring the environment setup specified has been done)
+
[IMPORTANT]
====
You first must set the following environment variables to log into your chosen image registry (e.g. `quay.io`):

* `USER`
* `PASSWORD`
====
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
----
mvn -B package -DskipTests \
        -Dquarkus.container-image.build=true \
        -Dquarkus.container-image.push=true \
        -Dquarkus.container-image.registry=quay.io \
        -Dquarkus.container-image.group=mhildenb \
        -Dquarkus.container-image.name=cdc-legacy-consumer \
        -Dquarkus.jib.base-jvm-image=registry.access.redhat.com/ubi8/openjdk-11@sha256:a6ad844fe15c91ae7a766c5c674c7c17b3a7ea082596ec823ef031d459b66b83 \
        -Dquarkus.container-image.username=pass:[${USER}] -Dquarkus.container-image.password=pass:[${PASSWORD}] \
        -Dquarkus.container-image.tag=latest \
        -f pass:[${DEMO_HOME}]/example/cdc-legacy-consumer
----

[#deploy]
== Deploying the Legacy App Consumer

Once the new image is built, you can deploy the `legacy-consumer` to the `${dev_prj}`, with the following command:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
oc apply -f pass:[${DEMO_HOME}]/example/cdc-legacy-consumer/kube/legacy-consumer-adaptor.yaml -n pass:[${dev_prj}]
----

[#testapp]
== Strategies for Testing Legacy App Consumer

There are a few different ways you can test the application

=== Produce a message on a topic

You can use the following command to send a pre-formatted file to the kafka cluster.  Assuming the correct topic, both local (`mvn quarkus:dev`) and deployed versions of the application should be able to consume this

[NOTE]
====
For this to work you need to ensure you are logged into the OpenShift cluster and that this variable is set to whatever topic you're wanting to watch. For example:

----
TOPIC=mssql-server-linux
----
====

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
echo $(cat pass:[${DEMO_HOME}]/example/cdc-legacy-consumer/src/test/resources/testCreateEvent.json) | oc exec -it demo-kafka-0 -n $dev_prj -- bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic pass:[${TOPIC}]
----

[#buildcoolstore]
== Building Coolstore Services

=== Catalog

Rebuild the catalog service using this command:

[NOTE]
====
Set these variables accordingly based on what images are defined in the provision_coolstore.yaml ansible task.  We will pass these to jib from the maven command line.

* *IMAGE*: `mhildema/catalog:cdc-demo`
* *USER*: `<your login to the registry>`
* *PASSWORD*: `<your password to the registry>`

For more information on parameters that can be provided to jib, see link:https://github.com/GoogleContainerTools/jib/tree/master/jib-maven-plugin#system-properties[here]
====

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
mvn -B compile com.google.cloud.tools:jib-maven-plugin:2.8.0:build -Djib.to.image=pass:[${IMAGE}] \
  -Djib.to.auth.username=pass:[{$USER}] -Djib.to.auth.password=pass:[${PASSWORD}] \
  -f pass:[${DEMO_HOME}]/coolstore/catalog-service
----

==== Testing Catalog Locally

. Uncomment the properties at the bottom of: ${DEMO_HOME}/coolstore/catalog-service/src/main/resources/application-default.properties
. Port forward to the inventory service
+
----
oc port-forward svc/inventory 8084:8080
----
+
. Port forward to the catalog database
+
----
oc port-forward svc/catalog-database 5432:5432
----
